{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 2001 - Business Practicum (Spring 2022)\n",
    "# Week 12: Prediction when outcome is categorical (i.e., classification)\n",
    "Hello! We are now in week 12. Last week we learned to make predictions when the outcome variable is continuous.\n",
    "\n",
    "This week we'll learn how to make predictions when the outcome variable is categorical -- specifically when the outcome is binary (yes/no, 1/0, will buy/ will not buy).\n",
    "\n",
    "## Here is an overview of the steps we need to take: (In fact, most things we learned from last week still apply here!)\n",
    "\n",
    "1. you need to read in the data and required packages\n",
    "2. you need to explore the data (e.g., plot distribution of a given variable, compute correlations between any pair of variables)\n",
    "3. you need to process the data (e.g., remove outliers, interpolate missing values, generate new columns/features)\n",
    "4. you need to split the data into training and testing\n",
    "    <br/><br/>\n",
    "    When predicting an outcome variable that is categorical, we are looking at a **classification** problem. Basically, we want to train an algorithm to help us *classify* future observations. One simple yet powerful classification model is called **logistic regression**.\n",
    "    <br/><br/>\n",
    "5. you need to train a classifier, such as a logistic regression, using the **training data**.\n",
    "6. you need to evaluate the classifier performance using the **test data**.\n",
    "\n",
    "Once we make sure the classification performance is satisfactory -- we are done! Keep in mind that usually people will experiment with different classification algorithms and pick the alogirthm that yields the best performance. Basically, all you need to do is repeat steps 5-6 using different algorithms and compare their prediction performance.\n",
    "\n",
    "**Make sure to read the slide deck for this week to get information on ways to evaluate prediction performance.**\n",
    "\n",
    "Below, lets take a look at an online advertising data set. **We want to predict whether a given user will click the ad (yes/no).** Since the outcome is binary, this is a **classification problem**, and we'll build a **logistic regression model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### below, import packages for logistic regression and performance evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to download the data file (advertising.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"advertising.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "data['Age'].hist(bins=20)\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will quickly check for missing values and either interpolate or drop observations if needed. However, this data set has been cleaned for us so no need to do anything here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()  ### no missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "In some cases you might want to generate more columns, called **feature engineering**, if you think those extra columns can help improve the prediction performance. (You can always do this regardless of whether the outcome variable is continuous or categorical!)\n",
    "\n",
    "Say for example we think **age^2** can help improve our prediction. (There is million other variables that we could potentially generate -- remember the goal is to make prediction, so the interpretation of why a given variable is included is not that important. We just care if the prediction is better with the new variables.)\n",
    "\n",
    "It's very easy to generate and incorporate the new variable into our pandas dataframe. Let's create a new column called Age2 to store the squared of age:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age2'] = data['Age']*data['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[['Age','Age2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done! Just need to make sure when we create the model later on we include both columns as predictors.\n",
    "We will also select some variables we think will be relevant for predictions to the list of predictors, and ignore the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Clicked on Ad']\n",
    "X = data[['Daily Time Spent on Site', 'Age', 'Age2', 'Area Income', 'Daily Internet Usage', 'Male']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make sure we split the data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a logistic regression model is similar to training a linear regression model. You just have to create a logistic regression object and then supply the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression() ## create a logistic regression object\n",
    "log_reg.fit(X_train, y_train)  ## fit (train) the logistic regression model with training data\n",
    "\n",
    "y_pred = log_reg.predict(X_test) ## make prediction based on the test set data's X variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "Keep in mind that to evaluate the classification performance **we need to compare the predicted results (y_pred) with the actual results (y_test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "## Below we use something called f-string to print results. It's just another way to print strings that allows us to\n",
    "## specify decimal places.\n",
    "##\n",
    "## For more information: https://realpython.com/python-f-strings/\n",
    "\n",
    "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyses done in the cell above show that our logistic regression performs really well. Out of 400 observatios in the test set, 188+191 = 379 was classified correctly (an accuracy of 94.75%). The other metrics also look pretty good (precision, recall, F1_score). Overall, this is a good model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, let's try running the model without the Age^2 term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.drop([\"Age2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.drop([\"Age2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg2 = LogisticRegression() ## create a logistic regression object\n",
    "log_reg2.fit(X_train2, y_train)  ## fit (train) the logistic regression model with training data\n",
    "\n",
    "y_pred2 = log_reg2.predict(X_test2) ## make prediction based on the test set data's X variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision2 = precision_score(y_test, y_pred2)\n",
    "recall2 = recall_score(y_test, y_pred2)\n",
    "f12 = f1_score(y_test, y_pred2)\n",
    "\n",
    "## Below we use something called f-string to print results. It's just another way to print strings that allows us to\n",
    "## specify decimal places.\n",
    "##\n",
    "## For more information: https://realpython.com/python-f-strings/\n",
    "\n",
    "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred2)}\")\n",
    "print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred2):.4f}\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision2:.4f}\\n\\tRecall: {recall2:.4f}\\n\\tF1_Score: {f12:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model without the Age^2 term performs worse than the model with it. Therefore, if we were to pick our final model between the two, **we will pick the model with Age^2 as out best prediction model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If we want to know each variable's coefficient, run this cell\n",
    "\n",
    "list(zip(X_train.columns,pd.Series(log_reg.coef_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict_proba(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
